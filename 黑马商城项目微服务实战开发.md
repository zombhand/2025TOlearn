# 黑马商城项目微服务实战开发

## 导入数据库

在黑马中导入数据使用docker进行自动化导入

```bash
docker run -d \
  --name mysql \
  -p 3307:3306 \
  -e TZ=Asia/Shanghai \
  -e MYSQL_ROOT_PASSWORD=123 \
  -v /root/mysql/data:/var/lib/mysql \
  -v /root/mysql/conf:/etc/mysql.conf.d \
  -v /root/mysql/init:/docker-entrypoint-initdb.d \
  --network hm-net \
  mysql
```

## 拆分服务

首先在父工程下新建个模块

然后把需要的依赖给引入

在新的工程的启动项上进行个注解

```java
@MapperScan("com.heima.item.mapper")
@SpringBootApplication
public class ItemServiceApplication {

    public static void main(String[] args) {
        SpringApplication.run(ItemServiceApplication.class, args);
    }

}
```

@MapperScan

作用：指定要变成实现类的接口所在的包，然后包下面的所有接口在编译之后都会生成相应的实现类

添加位置：是在SpringBoot启动类上面添加



#### 在配置中

需要注意的点:

1. 每个微服务名字各异
2. logging配置中
   1. level是输出级别
   2. fill-path 是文件的输出位置，保证每个服务的输出位置不同

```yaml
server:
  port: 8081
# 要给微服务起个名字
spring:
  application:
    name: item-service # 微服务名称
  profiles:
    active: dev
  datasource:
    url: jdbc:mysql://${hm.db.host}:3307/hmall?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai
    driver-class-name: com.mysql.cj.jdbc.Driver
    username: root
    password: ${hm.db.pw}
mybatis-plus:
  configuration:
    default-enum-type-handler: com.baomidou.mybatisplus.core.handlers.MybatisEnumTypeHandler
  global-config:
    db-config:
      update-strategy: not_null
      id-type: auto
logging:
  level:
    com.hmall: debug
  pattern:
    dateformat: HH:mm:ss:SSS
  file:
    path: "logs/${spring.application.name}"
knife4j:
  enable: true
  openapi:
    title: 黑马商城商品管理文档
    description: "黑马商城商品管理文档"
    email: zhanghuyi@itcast.cn
    concat: 虎哥
    url: https://www.itcast.cn
    version: v1.0.0
    group:
      default:
        group-name: default
        api-rule: package
        api-rule-resources:
          - com.heima.item.controller

```

## 注册中心

![image-20250116172100706](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250116172100706.png)

**服务治理中的三个角色分别是什么？**

- 服务提供者：暴露服务接口，供其它服务调用
- 服务消费者：调用其它服务提供的接口
- 注册中心：记录并监控微服务各实例状态，推送服务变更信息

**消费者如何知道提供者的地址？**

- 服务提供者会在启动时注册自己信息到注册中心，消费者可以从注册中心订阅和拉取服务信息

**消费者如何得知服务状态变更？**

- 服务提供者通过心跳机制向注册中心报告自己的健康状态，当心跳异常时注册中心会将异常服务剔除，并通知订阅了该服务的消费者

**当提供者有多个实例时，消费者该选择哪一个？**

- 消费者可以通过负载均衡算法，从多个实例中选择一个

**服务发现**

## 最佳实现

![image-20250116203538032](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250116203538032.png)

![image-20250116203654016](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250116203654016.png)



当定义的FeignClient不在SpringBootApplication的扫描包范围时，这些FeignClient无法使用。有两种方式解决：

方法一：指定FeignClient所在包

```java
@EnableFeignClients(basePackages = "com.hmall.api.clients")
```

方法二：指定FeignClient字节码

```java
@EnableFeignClients(clients = {UserClient.class})
```

## 网关

1. 创建新模块

2. 引入网关依赖

3. 编写启动类

4. 配置路由规则

   ```yaml
   spring:
   	cloud:
   		gataway:
   			routes:
   				- id : item # 路由规则id，自定义，唯一
   				  uri: lb://item-service # 路由目标微服务，lb代表负载均衡
   				  predicates: # 路由断言，判断请求是否符合规则，符合则路由到目标
   				  	- Paht=/items/** # 以请求路径做判断，以/items开头则符合
   				- id: xx
   			      uri: lb://xx-service
   			      predicates:
   			      	- Path=/xx/**
   ```

## 网关登录校验

![image-20250118012006394](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118012006394.png)

- 如何在网关转发之前做登录校验?
- 网关如何将用户信息传递给微服务？
- 如何在微服务之间传递用户信息？

## 自定义过滤器

网关过滤器有两种，分别是：

- GatewayFilter:路由过滤器，作用于任意指定的路由；默认不生效，要配置到路由后生效。
- GlobalFilter：全局过滤器，作用范围是所有路由;声明后自动生效。

两种过滤器的**过滤方法**签名完全一致：

![image-20250118012537329](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118012537329.png)

### 自定义过滤器GlobalFilter

自定义GlobalFilter比较简单，直接实现GlobalFilter接口即可：

```java
@Commpont
public class MyGlobalFilter implements GlobalFilter{
    
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        // 1.获取请求
        ServerHttpRequest request = exchange.getRequest();
        // 2.过滤器业务处理
        System.out.println("GlobalFilter pre阶段 执行了...");
        // 3.放行
        return chain.filter(exchange);
    }
    
    @Override
    public int getOrder() { // 用于确定优先级，返回数字越小优先级越高
        return 0; 
    }
}
```

## 网关传递用户到微服务



现在，网关已经可以完成登录校验并获取登录用户身份信息。但是当网关将请求转发到微服务时，微服务又该如何获取用户身份呢？

由于网关发送请求到微服务依然采用的是`Http`请求，因此我们可以将用户信息以请求头的方式传递到下游微服务。然后微服务可以从请求头中获取登录用户信息。考虑到微服务内部可能很多地方都需要用到登录用户信息，因此我们可以利用SpringMVC的拦截器来实现登录用户信息获取，并存入ThreadLocal，方便后续使用。

据图流程图如下：

![img](https://b11et3un53m.feishu.cn/space/api/box/stream/download/asynccode/?code=M2FjYTQ4MjRlOTVmYzhkNTBhNzA1NTE4YjRmYmNlODVfUDBqenRVSHc4UlhLT0hkVVlTNGUyR1Iwc3Y2TDVRbWhfVG9rZW46S2h4RWI2cmpCb05yVkN4c2VoTGNGUExFblNkXzE3MzcyMDY2NzY6MTczNzIxMDI3Nl9WNA)

接下来要做的事情有：

- 改造网关过滤器，在获取用户信息后保存到请求头，转发到下游微服务
- 编写微服务拦截器，拦截请求获取用户信息，保存到ThreadLocal后放行

1. 保存用户到请求头

   首先，修改登录校验拦截器的处理逻辑，保存用户信息到请求头中：

   ```java
   @Override
   public Mono<Void> filter (serverWebExchange exchange, GatewayFilterChain chain) {
       // 1.获取request
       ServerHttpRequest request = exchange.getRequest();
       // 2.判断是否需要做登录拦截
       if(isExclude(request.getPath().toString())){...}
       // 3.获取token
       String token = null;
       List<String> headers = request.getHeaders().get("authorization");
       if (headers != null && !headers.isEmpty()){...}
       // 4.校验并解析token
       Long userId = null;
       try {
           userId = jwtTool.parseToken(token);
       } catch (UnauthorizedException e)
       {...}
       // 5.传递用户信息
       String userInfo = userId.toString();
       ServerWebExchange ex = exchange.mutate()
           .request(b -> b.header("user-info", userInfo))
           .builf();
       // 6.放行
       return chain.filter(ex);
   }
   ```

2. 拦截器获取用户

   使用common包内的ThreadLocal工具

   接下来，只需要编写拦截器，获取用户信息并保存到UserContext，然后放行即可。

   由于每个微服务都有获取登录用户的需求，因此拦截器我们直接写在common中，并写好自动装配。这样微服务只需要接入common就可以直接具备拦截器功能，无需重复编写。

   在common模块内定义一个拦截器:

   ```java
   @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
       // 1.获取请求头中的用户信息
       String userInfo = request.getHeader("user-info");
       // 2.判断是否为空
       if (StrUtil.isNotBlank(userInfo)) {
           // 不为空，保存到ThreadLocal
           	UserContext.setUser(Long.valueOf(userInfo));
       }
       // 3.放行
       return true;
   }
   
   @Override
   public void afterCompletion(HttpServletRequest request, HttpServletResponse response){
       // 移除用户
       UserContext.removerUser();
   }
   ```

   接着编写SpringMVC的配置类，配置登录拦截器：

   ```java
   @Configuration
   @ConditionalOnClass(DispathcherServlet.class) // 排除网关避免冲突
   public class MvcConfig implements WebMvcConfigurer {
       @Override
       public void addInterceptors(InterceptorRegistry registry) {
           registry.addInterceptor(new UserInfoInterceptor());
       }
   }
   ```

   不过，需要注意的是，这个配置类默认是不会生效的，因为它所在的包是`com.hmall.common.config`，与其它微服务的扫描包不一致，无法被扫描到，因此无法生效。

   基于SpringBoot的自动装配原理，我们要将其添加到`resources`目录下的`META-INF/spring.factories`文件中：

   ```properties
   org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
     com.hmall.common.config.MyBatisConfig,\
     com.hmall.common.config.MvcConfig
   ```

   

![image-20250118220725647](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118220725647.png)

## 分布式事务

### 实现AT模式

首先要添加表到微服务对应的数据库中

然后修改application.yml文件，将事务模式修改为AT模式：

```yaml
seata:
	data-source-proxy-mode: AT # 开启数据源代理的AT模式
```



# 实用的点

### 工具类

其中的BeanUtil 很好用

```xml
<dependency>
            <groupId>cn.hutool</groupId>
            <artifactId>hutool-core</artifactId>
            <version>5.8.35</version>
</dependency>
```

### mybatisplus实用插件使用

![image-20250112174704016](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250112174704016.png)

### 查询集合时判空使用

```java
CollUtil.isEmpty(list);
// 为空的话返回一个
Collections.emptyList();
```



```java
// 已知ids获取对应用户
List<User> userList = listByIds(ids);
// 1获取用户id集合
List<Long> idList = userList.lambda().map(User::getId).collect(Collectors.toList());

// 2根据用户id查询地址
List<Address> address = Db.lambdaQuery(Address.class).in(Address::getUserId, userIds).list();
// 2.1获取用户id集合
List<Long> idList = userList.stream().map(User::getId).toList();
// 2.2根据用户id查询地址
List<Address> addressList = Db.lambdaQuery(Address.class).in(Address::getUserId, idList).lsit();
// 2.3转换地址VO
List<AddressVO> addressVOS = BeanUtil.copyToList(addressList, AddressVO.class);
// 2.4用户地址集合分组处理，相同用户的放入一个集合（组）中
Map<Long, List<AddressVO>> addressMap = new HashMap<>(0);
if(CollUtil.isNotEmpty(addressList)){
    addressMap = addressMap.stream().collect(Collectors.groupingBy(AddressVO::getUserId));
}
// 3.转换VO返回
List<UserVO> userVOList = new ArrayList<>(userList.size());
for (User user : userList) {
    // 3.1 转换UserPO为 VO
    UserVO vo = BeanUtil.copyProperties(user, UserVO.class);
    userVOlist.add(vo);
    // 3.2转换地址VO
    vo.setAddressVOList(addressMap.get(user.getId()));
}
```

### 状态字段的ENUM化

使用enmu类

```java
@Getter
public enum UserStatus {
    NORMAL(1, "正常"),
    FROZEN(2, "冻结"),
    ,
    @EnumValue
    private final int value;
    private final String desc;
    
    UserStatus(int value, String desc) {
        this.value = value;
        this.desc = desc;
    }
}
```

### JSON数据处理

对JSON化的数据项单独建个类

```java
@Data
@NoArgsConstructor
@AllArgsConstructor(staticName = "of")
public class UserInfo{
    private Integer age;
    private String intro;
    private String gender;
}
```

对实体类的JSON项进行注解

```java
@Data
@TableName(value = "user", autoResultMap = true)
public class User{
    /**
    *详细信息
    */
    @TableField(typeHandler = JasksonTypeHandler.class)
    private UserInfo info;
}
```

### 通用分页实体和MP转换

通用的PageQuery以UserQuery继承为例

```java
@EqualsAndHashCode(callSuper = true)
@Data
@ApiModel(description = "用户查询条件实体")
public class UserQuery extends PageQuery{
    @ApiModelProperty("用户关键字")
    private String name;
    @ApiModelProperty("用户状态：1-正常，2-冻结")
    private Integer status;
    @ApiModelProperty("余额最小值")
    private Integer minBalance;
    @ApiModelProperty("余额最大值")
    private Integer maxBalance;
}
```

```java
@Data
@ApiModel(description = "分页查询实体")
public class PageQuery{
    
    @ApiModelProperty("页码")
    private Integer pageNo = 1;
    @ApiModelProperty("页码")
    private Integer pageSize = 5;
    @ApiModelProperty("排序字段")
    private String sortBy;
    @ApiModelProperty("是否升序")
    private Boolean isAsc = true;
    
    public <T> Page<T> toMpPage(OrederItem ... itmes) {
        // 1.分页条件
        Page<T> page = Page.of(pageNo, pageSize);
        // 2.排序条件
        if(StrUtil.isNotBlank(sortBy)){
            //不为空
            page.addOrder(new OrderItem(sortBy, isAsc));
        }else if(items != null){
            // 为空，默认排序
            page.addOrder(items);
        }
        return page;
    }
    
    private <T> Page<T> toMpPage(String defaultSortBy, Boolean defaultAsc) {
        return toMpPage(new OrderItem(defaultSortBy, defaultAsc));
    }
    public <T> Page<T> toMpPageDefaultSortByCreateTime(){
        return toMpPage(new OrderItem("create_time", false));
    }
    public <T> Page<T> toMpPageDefaultSortByUpdateTime(){
        return toMpPage(new OrderItem("update_time", false));
    }
}
```

当PO和VO属性名相同时

```java
public static <PO, VO> pageDTO<VO> of(Page<PO> p, Class<VO> clazz){ // 泛型只是占位符不能获取它的字节符，所以需要调用者传入
    PageDTO<VO> dto = new PageDTO<>();
    // 1.总条数
    dto.setTotal(p.getTotal());
    // 2.总页数
	dto.setPages(p.getPages());
    // 3.当前页数据
    List<PO> records = p.getRecords();
    if (CollUtil.isEmpty(records)) {
        dto.setList(Collections.emptyList());
        return dto;
    }
    // 4.拷贝user的VO
    dto.setList(BeanUtil.copyToList(records, clazz));
    // 5.返回
    return dto;
}
```

当PO和VO属性名不同时

```java
public static <PO, VO> pageDTO<VO> of(Page<PO> p, Class<VO> clazz){ // 泛型只是占位符不能获取它的字节符，所以需要调用者传入
    PageDTO<VO> dto = new PageDTO<>();    
    // 1.总条数   
    dto.setTotal(p.getTotal());    
    // 2.总页数    
    dto.setPages(p.getPages());    
    // 3.当前页数据 
    List<PO> records = p.getRecords();    
    if (CollUtil.isEmpty(records)) {        dto.setList(Collections.emptyList());        return dto;    }    // 4.拷贝user的VO    
    dto.setList(records.stream().map(convertor).collect(Collectors.toList()));    
    // 5.返回    
    return dto;
}
```

调用案例

```java
@Override
Public PageDTO<UserVO> queryUsersPage(UserQuery query) {
    String name = query.getName();
    Integer status = query.getStatus();
    // 1.构建分页条件
    Page<User> page = query.toMpPageDefaultSortByUpdateTime();
    // 2.分页查询
    Page<User> p = lambdaQuery()
        			.like(name != null, User::getUsername, name)
        			.eq(status != null, User::getStatus, status)
        			.page(page);
    
    // 3.封装VO结果
    return PageDTO.of(p, user -> {
        // 1.拷贝基础属性
        UserVO vo = BeanUtil.copyProperties(user, UserVO.class);
        // 2.处理特殊逻辑
        vo.setUsername(vo.getUsername().subString(0, vo.getUsername().length() - 2) + "**");
        return vo;
    });
}
```

### 导入Bean

在类上加上@RequiredArgsConstructor

表示这个类在加载时要导入声明了final的属性

```java
@Service
@RequiredArgsConstructor
public class CartServiceImpl extends ServiceImpl<CartMapper, Cart> implements ICartService {
    
    private final RestTemplate  restTemplate;
}
```



# docker

```bash
docker run -d \
	--name mysql \
	-p 3306:3306 \
	-e TZ=Asia/Shanghai \
	-e MYSQL_ROOT_PASSWORD=123456 \
	mysql
```

- docker run: 创建并运行一个容器，-d 是让容器在后台运行
- --name mysql ：给容器起个名字，必须唯一
- -p 3306:3306 ：设置端口映射
- -e KEY=VALUE：是设置环境变量
- mysql：指定运行的镜像的名字

# 微服务

### 服务拆分原则

从拆分目标来说，要做到：

- 高内聚：每个微服务的职责要尽量单一，包含的业务相互关联度高、完整度高。
- 低耦合：每个微服务的功能要相对独立，尽量减少对其它微服务的依赖

拆分方式，两种方法：

- 纵向拆分：按照业务模块来拆分
- 横向拆分：抽取公共服务，提高复用性。

拆分后碰到的第一个问题是什么，如何解决？

- 拆分后，某些数据在不同服务，无法直接调用本地方法查询数据
- 利用RestTemplate发送Http请求，实现远程调用

# 远程调用

Spring给我们提供了一个RestTemplate工具，可以方便的实现Http请求的发送。使用步骤如下：

1. 注入RestTemplate到Spring容器

   ```java
   @Bean
   public RestTemplate restTemplate(){
       return new RestTemplate();
   }
   ```

2. 发起远程调用

   ```java
   public <T> ResponseEntity<T> exchange(
       String url, // 请求路径 -"http://localhost:8081/items?id={id}"
       HttpMethod method, // 请求方式	HttpMethod.GET
       @Nullable HttpEntity<?> requestEntity, // 请求实体，可以为空
       Class<T> responseType, // 返回值类型	User.class
       Map<String, ?> uriVariables // 请求参数	Map.of("id", "1")
   )
   ```

   实际调用案例

   ```java
   private void handleCartItems(List<CartVO> vos) {
       // 1.获取商品id
       Set<Long> itemIds = vos.stream().map(CartVO::getItemId).collect(Collectors.toSet());
       // 2.查询商品
       // List<ItemDTO> items= itemService.queryItemByIds(itemIds);
       // 2.1 利用RestTemplate 发起http请求，得到http的响应
       ResponseEntity<List<ItemDTO>> response = restTemplate.exchange(
       	"http://localhost:8081/items?ids={ids}",
           HttpMethod.GET,
           null,
           new ParameterizedTypeReference<List<ItemDTO>>(){},
           Map.of("ids",CollUtil.join(itemIds, ","))
       )
   }
   ```

   其中有几个点需要注意

   1. 在返回类型中由于比较复杂是一个LIST《ITEMDTO》的形式所以不能通过直接传一个class字节码来确定返回类型，所以使用new 一个类来解决
   2. 在Map的值中，由于对于Ids是一个字符串，不能用集合来传入，使用了hutool的工具CollUtil.join将集合内的参数以指定的字符连接起来，

# Nacos注册中心

Nacos是目前国内企业中占比最多的注册中心组件。它是阿里巴巴的产品，目前已经加入SpringCloudAlibaba中。

使用步骤

1. 导入nacos的数据库

2. 将`nacos/custom.env`的配置放入root目录

   ```
   PREFER_HOST_MODE=hostname
   MODE=standalone
   SPRING_DATASOURCE_PLATFORM=mysql
   MYSQL_SERVICE_HOST=	//改成自己数据库的地址
   MYSQL_SERVICE_DB_NAME=nacos
   MYSQL_SERVICE_PORT=3307	//改成自己数据库的端口
   MYSQL_SERVICE_USER=root	//改成自己数据库的姓名
   MYSQL_SERVICE_PASSWORD=123	//改成自己数据库的密码
   MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=Asia/Shanghai
   ```

3. 使用docker指令进行容器配置运行

   ```bash
   docker run -d \
   --name nacos \
   --env-file ./nacos/custom.env \
   -p 8848:8848 \
   -p 9848:9848 \
   -p 9849:9849 \
   --restart=always \
   nacos/nacos-server:v2.1.0-slim
   ```

   8848 是用于客户端与服务通信的主要端口。

   9848 是 gRPC 端口，用于与 Nacos 的 gRPC 通信（如果需要）。

   9849 是 Raft 端口，用于 Nacos 集群中节点之间的通信（如果运行集群模式）。

   启动完成后，访问下面地址：http://192.168.150.101:8848/nacos/，注意将`192.168.150.101`替换为你自己的虚拟机IP地址。

   首次访问会跳转到登录页，**账号密码都是nacos**

4. **服务注册**

   1. 引入依赖

      ```xml
      <!--nacos 服务注册发现-->
      <dependency>
      	<groupId>com.alibaba.cloud</groupId>
          <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
      </dependency>
      ```

   2. 配置Nacos地址

      ```yaml
      spring:
      	application:
      		name: item-service # 服务名称
      	cloud:
      		nacos:
      			server-addr: 192.168.150.101:8848 # nacos地址
      ```

5. **服务发现**

   **消费者**需要连接nacos以拉取和订阅服务，因此服务发现的前两步与服务注册是一样的，后面再加上服务调用即可：

   1. 引入 nacos discovery依赖

   2. 配置nacos地址

   3. 服务发现

      ```java
      private final DiscoveryClient discoveryClient;
      
      private void handleCartItems(List<CartVO> vos) {
          // 1.根据服务名称，拉取服务的实例列表
          List<ServiceInstance> instances = discoveryClient.getInstances("item-service");
          // 2.负载均衡，挑选一个实例
          ServiceInstance instance = instances.get(RandomUtil.randomInt(instances.size()));//传入一个负载均衡算法
          // 3.获取实例的IP和端口
          URI uri = instance.getUri();
          // ... 略
      }
      ```

## OpenFeign

OpenFeign是一个声明式的http客户端，是SpringCloud在Eureka公司开源的Feign基础上改造而来

原始的方法：

![image-20250116185255943](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250116185255943.png)

使用方法：

OpenFeign已经被SpringCloud自动装配，实现起来非常简单：

1. 引入依赖，包括OpenFeign和负载均衡组件SpringCloudLoadBalancer

   ```xml
   <!--OpenFeign-->
   <dependency>
   	<groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-openfeign</artifactId>
   </dependency>
   <!--负载均衡-->
   <dependency>
   	<groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-loadbalancer</artifactId>
   </dependency>
   ```

   springCloud原本用的是Ribbon而此项目用的是最新的loadbalancer

2. 通过@EnableFeignClients注解，启用OpenFeign功能

   ```java
   @EnableFeignClients
   @SpringBootApplication
   public class CartApplication {}
   ```

3. 编写FeignClient

   ```java
   @FeignClient(value = "item-service")
   public interface ItemClient {
       @GetMapping("/items")
       List<ItemDTO> queryItemByIds(@RequestParam("ids" Collection<Long> ids));
   }
   ```

   

4. 使用FeignClient,实现远程调用

   ```java
   List<ItemDTO> items = itemClient.queryItemByIds(List.of(1,2,3));
   ```

## 连接池

OpenFeign对Http请求做了优雅的伪装，不过其底层发起了http请求，依赖于其它的框架。这些框架可以自己选择，包括以下三种：

- HttpURLConnection: 默认实现，不支持连接池
- Apache HttpClient：支持连接池
- OKHttp支持连接池

OpenFeign整合OKHttp的步骤如下：

1. 引入依赖

   ```xml
   <!--ok-http-->
   <dependency>
   	<groupId>io.github.openfeign</groupId>
       <artifactId>feign-okhttp</artifactId>
   </dependency>
   ```

2. 开启连接池功能

   ```yaml
   feign:
   	okhttp:
   		enabled: true # 开启OKHttp连接池支持
   ```

   

## 日志

OpenFeign 只会在FeignClient所在包的日志级别为DEBUG时，才会输出日志。而且其日志级别有4级：

- **NONE**：不记录任何日志信息，这是默认值。
- **BASIC**：仅记录请求的方法，URL以及响应状态码和执行时间
- **HEADERS**：在BASIC的基础上，额外记录了请求和响应的头信息
- **FULL**：记录所有请求和响应的明细，包括头信息、请求体、元数据

由于Fegin默认的日志级别就是NONE，所以默认我们看不到请求日志

要自定义日志级别需要声明一个类型为Logger.Level的Bean，在其中定义日志级别：

```java
public class DefaultFeignConfig {
    @Bean
    public Logger.Level feignLogLevel(){
        return Logger.Level.FULL;
    }
}
```

但此时这个Bean并未生效，要想配置某个FeignClient的日志，可以在@FeignClient注解中声明：

```java
@FeignClient(value = "item-service", configuration = DefaultFeignConfig.class)
```

如果想要**全局配置**，让所有FeignClient都按照这个日志配置，则需要在@EnableFeignClients注解中声明：

```java
@EnableFeignClients(defaultConfiguration = DefaultFeignConfig.class)
```

# 网关

网关：就是网络的关口，负责请求的路由、转发、身份校验。

![image-20250117224049562](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250117224049562.png)

![image-20250117224600799](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250117224600799.png)

## 路由属性

网关路由对应的Java类型是RouteDefinition,其中常见的属性有：

- id：路由唯一标识
- uri：路由目标地址
- predicates：路由断言，判断请求是否符合当前路由。
- filters：路由过滤器，对请求或响应做特殊处理。

## 路由断言

![image-20250118004509765](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118004509765.png)

## 路由过滤器

网关中提供了33中路由过滤器，每种过滤器都有独特的作用。

![image-20250118004835260](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118004835260.png)

如何统一添加过滤器

```yaml
spring:
	cloud:
		gataway:
			routes:
				- id : item # 路由规则id，自定义，唯一
				  uri: lb://item-service # 路由目标微服务，lb代表负载均衡
				  predicates: # 路由断言，判断请求是否符合规则，符合则路由到目标
				  	- Paht=/items/** # 以请求路径做判断，以/items开头则符合
			default-filters:
				- AddRequestHeader=truth, anyone long-press
				
```

在routes同级中配置默认过滤器即可

# 网关请求处理流程

![image-20250118011627866](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118011627866.png)

步骤一、在网关的登录校验过滤器中，把获取到的用户写入请求头

需求：修改gateway模块中的登录校验拦截器，在校验成功后保存用户到下游请求的请求头中。

提示：要修改转发到微服务的请求，需要用到ServerWebExchange类提供的API，示例如下：

```java
exchange.mutate() // mutate就是对下游请求做更改
    .request(builder -> builder.header("user-info", userInfo))
    .build();
```

步骤二、在hm-common中编写SpringMVC拦截器，获取登录用户

需求：由于每个微服务都可能有获取登录用户的需求，因此我们直接在hm-common模块定义拦截器，这样微服务只需要引入依赖即可生效，无需重复编写

# 配置管理

- 微服务重复配置过的，维护成本高
- 业务配置经常变动，每次修改都要重启服务
- 网关路由配置写死，如果变更要重启网关

![image-20250118231041026](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118231041026.png)

## 配置共享

1. 添加配置到Nacos

   添加一些共享配置到Nacos中

2. 拉取共享配置

   基于NacosConfig拉取共享配置代替微服务的本地配置。

   ![image-20250118232605575](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118232605575.png)

   1. 引入依赖

      ```xml
      <!--nacos配置管理-->
      <dependency>
      	<groupId>com.alibaba.cloud</groupId>
          <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
      </dependency>
      <!--读取bootstrap文件-->
      <dependency>
      	<groupId>org.springframework.cloud</groupId>
          <artifactId>spring-cloud-starter-bootstrap</artifactId>
      </dependency>
      ```

   2. 新建bootstrap.yaml

      ```yaml
      spring:
      	application:
      		name: cart-service # 服务名称
      	profiles:
      		active: dev
      	cloud:
      		nacos:
      			server-addr: 192.168.150.101 # nacos地址
      			shared-configs: # 共享配置
      				- dataId: shared-jdbc.yaml # 共享mybatis配置
      				- dataId: shared-log.yaml # 共享日志配置
      				- dataId: shared-swagger.yaml # 共享日志配置
      ```

   

## 配置热更新

配置热更新：当修改配置文件中的配置时，微服务无需重启即可使配置生效。

前提条件：

1. nacos中要有一个于微服务名有关的配置文件。

   ![image-20250118234348923](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118234348923.png)

2. 微服务中要以特定方式读取需要热更新的配置属性

   ![image-20250118234618623](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250118234618623.png)



## 动态路由

# 雪崩问题

微服务调用链路中的某个服务故障，引起整个链路中的所有微服务都不可用，这就是雪崩。

雪崩问题产生的原因是什么？

- 微服务相互调用，服务提供者出现故障或阻塞。
- 服务调用者没有做好异常处理，导致自身故障。
- 调用链中的所有服务级联失败，导致整个集群故障

解决问题的思路有哪些？

- 尽量避免服务出现故障或阻塞
  - 保证代码的健壮性；
  - 保证网络畅通；
  - 能应对较高的并发请求；
- 服务调用者做好远程调用异常的后备方案，避免故障扩撒

## 服务保护方案 -请求限流

请求限流：限制访问微服务的请求的并发量，避免服务因流量激增出现故障。

![image-20250119020040524](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250119020040524.png)

![image-20250119020056308](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250119020056308.png)

## 服务保护方案 -线程隔离

线程隔离：也叫做舱壁模式，模拟船舱隔板的防水原理。通过限定每个业务能使用的线程数量而将故障业务隔离，避免故障扩散。

![image-20250119020430214](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250119020430214.png)

## 服务保护方案 -服务熔断

服务熔断：由断路器统计请求的异常比例或慢调用比例，如果超出阈值则会**熔断**该业务，则拦截该接口的请求。

熔断期间，所有请求快速失败，全都走fallback逻辑。

![image-20250119020943891](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250119020943891.png)

## 服务保护技术

|          | Sentinel                                       | Hystrix                      |
| -------- | ---------------------------------------------- | ---------------------------- |
| 线程隔离 | 信号量隔离                                     | 线程池隔离、信号量隔离       |
| 熔断策略 | 基于慢调用比例异常比例                         | 基于异常比率                 |
| 限流     | 基于 QPS，支持流量整形                         | 有限的支持                   |
| Fallback | 支持                                           | 支持                         |
| 控制台   | 开箱即用，可配置规则、查看秒级监控、机器发现等 | 不完善                       |
| 配置方式 | 基于控制台，重启后失效                         | 基于注解或配置文件，永久生效 |

# Sentinel

Sentinel是阿里巴巴开源的一款微服务流量控制组件。

Sentinel 的使用可以分为两个部分:

- **核心库**（Jar包）：不依赖任何框架/库，能够运行于 Java 8 及以上的版本的运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。在项目中引入依赖即可实现服务限流、隔离、熔断等功能。
- **控制台**（Dashboard）：Dashboard 主要负责管理推送规则、监控、管理机器信息等。

将jar包放在任意非中文、不包含特殊字符的目录下，重命名为`sentinel-dashboard.jar`：

然后运行如下命令启动控制台：

```Shell
java -Dserver.port=8090 -Dcsp.sentinel.dashboard.server=localhost:8090 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar
```

## 簇点链路

簇点链路，就是单机调用链路。是一次请求进入服务后经过的每一个被Sentinel监控的资源链。默认Sentinel会监控SpringMVC的每一个Endpoint(http接口)。限流、熔断等都是针对簇点链路中的**资源**设置的。而资源名默认就是接口的青秀区路径

Restful风格的API请求路径一般都相同，这会导致簇点资源名称重复。因此我们要修改配置，把请求方式+请求路径作为簇点资源名称：

## 实现管控

对请求做流控规则-线程数是设置单个线程最大访问数量，QPS是设置

## Fallback

当线路的某个服务不可用时，避免持续的调用失败，直接走一个fallback的方法，以其它方式返回提示数据

1. 将FeignClient作为Sentinel的簇点资源：

   ```yaml
   feign:
   	sentinel:
   		enabled: true
   ```

2. FeignClient的Fallback有两种配置方式：

   - 方式一：FallbackClass，无法对远程调用的异常做处理
   - 方式二：FallbackFactory，可以对远程调用的异常做处理，通常会选择这种

步骤一：自定义类，实现FallbackFactory，编写对某个FeignClient的fallback逻辑：

```java
@Slf4j
public class UserClientFallbackFactory implements FallbackFactory<UserClient> {
    @Override
    public UserClient create(Throwable throwable) {
        // 创建UserClient接口实现类，实现其中的方法，编写失败降级的处理逻辑
        return new UserClient() {
            @Override
            public User findById(Long id) {
                // 记录异常信息，可以返回空或抛出异常
                log.error("查询用户失败", throwable);
                return null;
            }
        }
    }
}
```

步骤二：将刚刚定义的UserClientFallbackFactory注册为一个Bean：

```java
@Bean
public UserClientFallbackFactory userClientFallback(){
    return new UserClientFallbackFactory();
}
```

步骤三：在UserClient接口中使用UserClientFallbackFactory：

```java
@FeignClient(value = "userservice", fallbackFactory = UserClientFallbackFactory.class)

public interface UserClient {
    
    @GetMapping("/user/{id}")
    Useer findById(@PathVariable("id") Long id);
}
```

## 服务熔断

熔断降级是解决雪崩问题的重要手段。思路是由**断路器**统计服务调用的异常比例、慢请求比例，如果超出阈值则会**熔断**该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行该服务的请求。

![image-20250120230311588](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250120230311588.png)

# 分布式事务

下单业务，前端请求首先进入订单服务，创建订单并写入数据库。然后订单服务调用购物车服务和库存服务：

- 购物车服务负责清理购物车信息
- 库存服务负责扣减商品库存

![image-20250121003614625](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121003614625.png)

在分布式系统中，如果一个业务需要多个服务合作完成，而且每一个服务都有事务，多个事务必须同时成功或失败，这样的事务就是**分布式事务**。其中的每个服务的事务就是一个分支事务。整个业务称为一个**全局事务**。

# Seata

Seata是 2019 年  1月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。

官网地址：http://seata.io/,其中的文档、博客提供了大量的使用说明、源码分析。

## 分布式事务解决思路

解决分布式事务，各个子事务之间必须能感知到彼此的事务关系，才能保证状态一致。

![image-20250121004329786](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121004329786.png)

## Seata架构

Seata事务管理中有三个重要的角色：

- TC(Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。
- TM(Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。
- RM(Resource Manager) - 资源管理器：管理分支事务，与TC交谈以注册分支事务和报告分支事务的状态

![image-20250121010037712](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121010037712.png)

## Seata的使用

1. 首先导入数据库表

2. 导入配置文件到虚拟机中

   ```yaml
   server:
     port: 7099		# Web控制台端口
   
   spring:
     application:
       name: seata-server		# 微服务名称
   
   logging:
     config: classpath:logback-spring.xml	# 日志位置
     file:
       path: ${user.home}/logs/seata
     # extend:
     #   logstash-appender:
     #     destination: 127.0.0.1:4560
     #   kafka-appender:
     #     bootstrap-servers: 127.0.0.1:9092
     #     topic: logback_to_logstash
   
   console:
     user:
       username: admin
       password: admin
   
   seata:
     config:
       # support: nacos, consul, apollo, zk, etcd3
       type: file		# 配置方式 以上是其它可选的方案
       # nacos:
       #   server-addr: nacos:8848
       #   group : "DEFAULT_GROUP"
       #   namespace: ""
       #   dataId: "seataServer.properties"
       #   username: "nacos"
       #   password: "nacos"
     registry:
       # support: nacos, eureka, redis, zk, consul, etcd3, sofa
       type: nacos
       nacos:
         application: seata-server 
         server-addr: nacos:8848 # 需要容器在同一网络下
         group : "DEFAULT_GROUP"
         namespace: ""
         username: "nacos"
         password: "nacos"
   #  server:
   #    service-port: 8091 #If not configured, the default is '${server.port} + 1000'
     security:
       secretKey: SeataSecretKey0c382ef121d778043159209298fd40bf3850a017
       tokenValidityInMilliseconds: 1800000
       ignore:
         urls: /,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/api/v1/auth/login
     server:
       # service-port: 8091 #If not configured, the default is '${server.port} + 1000'
       max-commit-retry-timeout: -1
       max-rollback-retry-timeout: -1
       rollback-retry-timeout-unlock-enable: false
       enable-check-auth: true
       enable-parallel-request-handle: true
       retry-dead-threshold: 130000
       xaer-nota-retry-timeout: 60000
       enableParallelRequestHandle: true
       recovery:
         committing-retry-period: 1000
         async-committing-retry-period: 1000
         rollbacking-retry-period: 1000
         timeout-retry-period: 1000
       undo:
         log-save-days: 7
         log-delete-period: 86400000
       session:
         branch-async-queue-size: 5000 #branch async remove queue size
         enable-branch-async-remove: false #enable to asynchronous remove branchSession
     store:
       # support: file 、 db 、 redis
       mode: db
       session:
         mode: db
       lock:
         mode: db
       db:
         datasource: druid
         db-type: mysql
         driver-class-name: com.mysql.cj.jdbc.Driver
         url: jdbc:mysql://mysql:3307/seata?rewriteBatchedStatements=true&serverTimezone=UTC
         user: root
         password: 123
         min-conn: 10
         max-conn: 100
         global-table: global_table
         branch-table: branch_table
         lock-table: lock_table
         distributed-lock-table: distributed_lock
         query-limit: 1000
         max-wait: 5000
       # redis:
       #   mode: single
       #   database: 0
       #   min-conn: 10
       #   max-conn: 100
       #   password:
       #   max-total: 100
       #   query-limit: 1000
       #   single:
       #     host: 192.168.150.101
       #     port: 6379
     metrics:
       enabled: false
       registry-type: compact
       exporter-list: prometheus
       exporter-prometheus-port: 9898
     transport:
       rpc-tc-request-timeout: 15000
       enable-tc-server-batch-send-response: false
       shutdown:
         wait: 3
       thread-factory:
         boss-thread-prefix: NettyBoss
         worker-thread-prefix: NettyServerNIOWorker
         boss-thread-size: 1
   
   ```

   ![image-20250121013316737](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121013316737.png)

   ![image-20250121013332847](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121013332847.png)

3. `docker network ls`查询各个容器网络端口

   `docker inspect mysql`查询（mysql）容器存在于哪个网络

   `docker logs -f seata` 查看日志 

4. 在虚拟机进行安装在/root目录下执行

   ```shell
   docker run --name seata \
   -p 8099:8099 \		# 微服务和seata的端口
   -p 7099:7099 \		# web 控制台的端口
   -e SEATA_IP=192.168.150.101 \
   -v ./seata:/seata-server/resources \
   --privileged=true \
   --network hm-net \
   -d \
   seataio/seata-server:1.5.2
   ```

## 微服务集成Seata

首先，要在项目中引入Seata依赖：

```xml
<!--统一配置管理-->
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
  </dependency>
  <!--读取bootstrap文件-->
  <dependency>
      <groupId>org.springframework.cloud</groupId>
      <artifactId>spring-cloud-starter-bootstrap</artifactId>
  </dependency>
  <!--seata-->
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
  </dependency>
```

然后，在application.yml中添加配置，让微服务找到TC服务地址：

![image-20250121021521705](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121021521705.png)

## XA模式

XA 规范是 X/Open组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准，XA规范 描述了全局的TM与局部的RM之间的接口，几乎所有主流的关系型数据库都对XA规范 提供了支持。Seata的XA模型如下：

![image-20250121024654605](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121024654605.png)

一阶段的工作：

1. RM注册分支事务到TC
2. RM执行分支业务sql但不提交
3. RM报告执行状态到TC

二阶段的工作：

- TC检测各分支事务执行状态

  a.	如果都成功，通知所有RM提交事务

  b.	如果有失败，通知所有RM回滚事务

- RM接收TC指令，提交或回滚事务

XA模式的优点是什么？

- 事务的强一致性，满足ACID原则。
- 常用数据库都支持，实现简单，并且没有代码侵入

XA模型的缺点是什么？

- 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差
- 依赖关系型数据库实现事务

Seata的starter已经完成了XA模式的自动装配，实现非常简单，步骤如下：

1. 修改application.yml文件（每个参与事务的微服务），开启XA模式：

   ```yaml
   seata:
   	data-source-proxy-mode: XA # 开启数据源代理的XA模式
   ```

2. 给发起全局事务的入口方法添加@GlobalTransactional注解，本例中是OrderServiceImpl中的create方法：

   ```java
   @Override
   @GlobalTransactional
   public Long createOrder(){
       
   }
   ```

3. 重启服务并测试

## AT模型

Seata主推的是AT模型，AT模型同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。

阶段一RM的工作：

- 注册分支事务
- 记录undo-log（数据快照）
- 执行业务sql并提交
- 报告事务状态

阶段二提交时RM的工作：

- 删除undo-log即可

阶段二回滚时RM的工作：

- 根据undo-log恢复数据到更新前

![image-20250121030056697](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250121030056697.png)

AT模式与XA模式最大的区别是什么？

- XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。
- XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。
- XA模式强一致；AT模式最终一致

# RabbitMQ

高性能的异步通讯组件

## 同步调用

![image-20250123001758791](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250123001758791.png)

同步调用的优势是什么？

- 时效性强，等待到结果后才返回

同步调用的问题是什么？

- 拓展性差
- 性能下降
- 级联失败问题

## 异步调用

![image-20250123002526896](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250123002526896.png)

异步调用的优势是什么？

- 耦合度低，拓展性强
- 异步调用，无需等待，性能好
- 故障隔离，下游服务故障不影响上游业务
- 缓存消息，流量削峰填谷

异步调用的问题是什么？

- 不能立即得到调用结果，时效性差
- 不确定下游业务执行是否成功
- 业务安全依赖于Broker的可靠性

## MQ技术选型

![image-20250123003732450](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250123003732450.png)

## RabbitMQ部署

```bash
docker run \
 -e RABBITMQ_DEFAULT_USER=itheima \
 -e RABBITMQ_DEFAULT_PASS=123321 \
 -v mq-plugins:/plugins \
 --name mq \
 --hostname mq \
 -p 15672:15672 \
 -p 5672:5672 \
 --network hm-net\
 -d \
 rabbitmq:3.8-management
```

可以看到在安装命令中有两个映射的端口：

- 15672：RabbitMQ提供的管理控制台的端口
- 5672：RabbitMQ的消息发送处理接口

## 基本介绍

RabbitMQ的整体架构及核心概念：

- virtual-host: 虚拟主机，起到数据隔离的作用

- publisher:消息发送者
- consumer:消息的消费者
- queue：队列，存储消息
- exchange：交换机，负责路由信息

![image-20250123011406585](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250123011406585.png)

消息发送的注意事项有哪些？

- 交换机只能路由消息，无法存储消息
- 交换机只会路由消息给与其绑定的队列，因此队列必须与交换机绑定

## 数据隔离

需求：在RabbitMQ的控制台完成下列操作：

- 新建一个用户hmall
- 为hmall用户创建一个virtual host
- 测试不同virtual host之间的数据隔离现象

## Java 客户端

![image-20250123014238040](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250123014238040.png)

1. 引入spring-amqp依赖

   在父工程中引入spring-amqp依赖，专业publisher和consumer服务都可以使用：

   ```xml
   <!--AMQP依赖，包含RabbitMQ-->
   <dependency>
   	<groupId>org.springframework.boot</groupId>
       <artifactId>spring-boot-starter-amqp</artifactId>
   </dependency>
   ```

2. 配置RabbitMQ服务端信息

   在每个微服务中引入MQ服务端信息，这样微服务才能连接到RabbitMQ

   ```yaml
   spring:
   	rabbitmq:
   		host: 192.168.150.101 # 主机名
   		port: 5672 # 端口
   		virtual-host: /hmall # 虚拟主机
   		username: hmall # 用户名
   		password: 123 # 密码
   ```

3. 发送消息

   SpringAMQP提供了Rabbit Template工具类，方便我们发送消息。发送消息代码如下：

   ```java
   @Autowired
   private RabbitTemplate rabbitTemplate;
   
   @Test
   public void testSimpleQueue() {
       // 队列名称
       String queueName = "simple.queue";
       // 消息
       String message = "hello, spring amqp!";
       // 发送消息
       rabbitTemplate.converAndSend(queueName, message);
   }
   ```

4. 接收消息

   SpringAMQP提供声明式的消息监听，我们只需要通过**注解**在方法上声明要监听的队列名称，将来SpringAMQP就会把消息传递给当前方法：

   ```java
   @Sl4j
   @Componet
   public class SpringRabbitListener {
       
       @RabbitLisener(queues = "simple.queue")
       public void listenSimpleQueueMessage(String msg) throws InterruptedException {
           log.info("spring 消费者接收到消息：[" + msg + "]")
       }
   }
   ```

## Work Queues

Work queues，任务模型。简单来说就是让**多个消费者绑定到一个队列，共同消费队列中的消息。**

**消息者信息推送限制**

默认情况下，RabbitMQ的会将消息轮询投递给绑定在队列上的每一个消费者。但这并没有考虑到消费者是否已经处理完消息，可能出现消息堆积。

因此需要修改配置，将preFetch值为1，确保同一时刻最多投递给消费者1条消息：

```yaml
spring:
	rabbitmq:
		listener:
			simple:
				prefetch: 1 # 每次只能获取一条消息，处理玩才能获取下一条消息
```

Work模型的使用：

- 多个消费者绑定到一个队列，可以加快消息处理速度
- 同一条消息只会被一个消费者处理
- 通过设置prefetch来控制消费者预取的消息数量，处理完一条再处理下一条，实现能者多劳

## 交换机

交换机的作用主要是**接收**发送者发送的消息，并将消息**路由**到与其绑定的队列。

常见交换机的类型有以下三种：

- Fanout：广播
- Direct：定向
- Topic：话题

### Fanout交换机

Fanout Exchange 会将接收到的消息路由到每一个跟其绑定的queue，所以也叫**广播模式**。



交换机的作用是什么？

- 接收publisher发送的消息
- 将消息按照规则路由到与之绑定的队列
- FanoutExchange的会将消息路由到每个绑定的队列

发送消息到交换机的API是怎样的？

```java
@Text
public void testFanoutExchange() {
    // 交换机名
    String exchangeName = "itcast.fanout";
    // 消息
    String messsage = "hello, everyone!";
    // 发送消息，参数分别是：交互机名称，RoutingKey(暂时为空)、消息
    rabbitTemplate.converAndSend(exchangeName, "", message);
}
```

### Direct交换机

Direct Exchange 会将接收到的消息根据规则路由到指定的Queue，因此称为**定向**路由。

- 每一个Queue都与Exchange设置一个BindingKey
- 发布者发送消息时，指定消息的RoutingKey
- Exchange将消息路由到BindingKey与消息RoutingKey一致的队列

描述下Direct交换机与Fanout交换机的差异？

- Fanout交换机将消息路由给每一个与之绑定的队列
- Direct交换机根据RoutingKey判断路由给哪个队列
- 如果多个队列具有相同的RoutingKey，则与Fanout功能类似

### Topic交换机

TopicExchange也是基于RoutingKey做消息路由，但是routingKey通常是多个单词的组合，并且以.分割。

Queue与Exchange指定BindingKey时可以使用通配符：

- #：代表0个或多个单词
- *：代表一个单词

## 声明队列和交换机

SpringAMQP提供了几个类，用来声明队列、交换机及其绑定关系：

- Queue：用于声明队列，可以用工厂类QueueBuilder构建
- Exchange：用于声明交换机，可以用工厂类ExchangeBuilder构建
- Binding：用于声明队列和交换机的绑定关系，可以用工厂类BindingBuilder构建

![image-20250123184550317](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250123184550317.png)

### 基于Bean

例如，声明一个Fanout类型的交换机，并且创建队列与其绑定：

```java
@Configuration
public class FanoutConfig {
    // 声明FanoutExchange交换机
    @Bean
    public FanoutExchange fanoutExchange(){
        return new FanourExchange("hmall.fanout");
    }
    // 声明第一个队列
    @Bean
    public Queue fanoutQueue1() {
        return new Queue("fanout.queue1");
    }
    // 绑定队列1和交换机
    @Bean
    public Binging bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange) {
        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);
    }
    // ... 略，以相同方式声明第二个队列，并完成绑定
}
```

```java
// 第二章构建交换机和队列方法
@Configuration
public class FanoutConfig {
    // 声明FanoutExchange交换机
    @Bean
    public FanoutExchange fanoutExchange(){
        return ExchangeBuilder
            		.fanoutExchange("hmall.fanout").build();
    }
    // 声明第一个队列
    @Bean
    public Queue fanoutQueue1(){
        return QueueBuilder.durable("fanout.queue1").build();
    }
}
```

### 基于注解

SpringAMQP还提供了基于@RabbitListener注解来声明队列和交换机的方式：

```java
@RabbitListener(bindings = @QueueBinding(
	value = @Queue(name = "direct.queue1"),
    exchange = @Exchange(name = "itcast.direct", type = ExchangeTypes.DIRECT),
    key = {"red", "blue"}
))
public void listenDirectQueue1(String msg) {
    System.out.println("消费者1接收到Direct消息：[" + msg+ "]");
}
```

## 消息转换器

Spring的对消息对象的处理是由org.springframework.amqp.support.converter.MessageConverter来处理的。而默认实现是SimpleMessageConverter，基于JDK的ObjectOutputStream完成序列化

存在下列问题：

- JDK的序列化有安全风险
- JDK序列化的消息太大
- JDK序列化的消息可读性差

推荐采用JSON序列化代替默认的JDK序列化，要做两件事情：

在publisher和consumer中都要引入jackson依赖：

```xml
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
</dependency>
```

在publisher和consumer中都要配置MessageConverter:

```java
@Bean
public MessageConverter messageConverter() {
    return new Jackson2JsonMessageConverter();
}
```

# RabbitMQ高级

## 发送者可靠性

### 发送者重连

有的时候由于网络波动，可能会出现发送者连接MQ失败的情况。通过配置我们可以开启连接失败后的重连机制：

```yaml
spring:
	rabbitmq:
		connection-timeout: 1s # 设置MQ的连接超时时间
		template:
			retry:
				enabled: true # 开启超时重试机制
				initial-interval: 1000s # 失败后的初始等待时间
				multiplier: 1 # 失败后下次的等待时长倍数，下次等待时长 = inital-interval * multiplier
				max-attempts: 3 # 最大重试次数
```

**注意：**当网络不稳定时，利用重试机制可以有效提高消息发送的成功率。不过SpringAMQP提供的重试机制是**阻塞式**的重试，也就是说多次重试等待的过程中，当前线程是阻塞的，会影响业务性能。

如果对于业务性能有要求，建议禁用重试机制，如果要用也要合理的去配置等待时长和重试次数。当然也可以考虑使用异步线程来执行发送消息的代码。 

### 发送者确认

SpringAMQP提供了Publisher Confirm和Publisher Return两种确认机制。开启确认机制后，当发送者发送消息到MQ后，MQ会返回确认结果给发送者。返回的结果有以下几种情况：

- 消息投递到了MQ，但是路由失败。此时会通过PublisherReturn返回路由异常原因，然后返回ACK，告知投递成功
- 临时消息投递到了MQ，并且入队成功，返回ACK，告知投递成功
- 持久消息投递到了MQ，并且入队完成持久化，返回ACK，告知投递成功
- 其它情况都会返回NACK，告知投递失败

实现

1. 在微服务中添加配置：

   ```yaml
   spring:
   	rabbitmq:
   		publisher-confirm-type: correlated # 开启publisher confirm机制，并设置confirm类型
   		publisher-returns: true # 开启publisher return机制
   ```

   配置说明：

   - 这里的publisher-confirm-type有三种模式可选：
     - none:关闭confirm机制
     - simple：同步阻塞等待MQ的回执消息
     - correlated: MQ异步回调方式返回回执消息

2. 在每个RabbitTemplate只能配置一个ReturnCallback, 因此需要在项目启动过程中配置：

   ```java
   @Sl4j
   @AllArgsConstructor
   @Configuration
   public class MqConfig {
       private final RabbitTemplate rabbitTemplate;
       
       @PostConstruct
       public void init(){
           rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnCallback() ) {
               @Override
               public void returnedMessage(ReturnedMessage returned) {
                   log.error("触发return callback,"),
                   log.debug("exchange:{}", returned.getExchange());
                   log.debug("routingKey: {}", returned.getRoutingKey());
                   log.debug("message: {}", returned.getMEssage());
                   log.debug("replyCode: {}", returned.getReplyCode());
                   log.debug("replyText: {}", returned.getReplyText());
               }
           }
       }
   }
   ```

3. 发送消息，指定消息ID、消息ConfirmCallback

   ```java
   @Test
   void testPublisherConfirm() throws InterruptedException {
       // 1.创建CorrelationData
       CorrelationData cd = new CorrelationData();
       // 2.给Future添加ConfirmCallback
       cd.getFuture().addCallback(new ListenableFutureCallback<CorrelationData.Confirm>() {
           @Override
           public void onFailuer(Throwable ex) {
               // 2.1 Future发生异常时的处理逻辑，基本不会触发
               log.error("handle message ack fail", ex);
           }
           @Override
           public void onSuccess(CorrelationData.Confirm result) {
               // 2.2 Future接收到回执的处理逻辑，参数中的result就是回执内容
               if(result.isAck()) { // result.isAck(), boolean类型，true代表ack回执，false 代表 nack回执
               	log.debug("发送消息成功，收到 ack!");
               }
               else { // reuslt.getReason()，String类型，返回nack时的异常描述
                   log.error("发生消息失败，收到ncak,reason ： {}", result.getReason());
               }
           }
       }); 
       // 3. 发送消息
       rabbitTemplate.converAndSend("hmall.direct", "red1", "hello", cd);
   }
   ```

   

## MQ可靠性

在默认情况下，RabbitMQ会将接收到的信息保存在内存中以降低消息收发的延迟。这样会导致两个问题：

- 一旦MQ宕机，内存中的消息会丢失
- 内存空间有限，当消费者故障或处理过慢时，会导致消息积压，引发MQ阻塞

### 数据持久化

RabbitMQ实现数据持久化包括3个方面：

- 交换机持久化
- 队列持久化
- 消息持久化

### Lazy Queue

用RabbitMQ的3.6.0版本开始，就增加了Lazy Queue的概念，也就是**惰性队列**。

惰性队列的特征如下：

- 接收到消息后直接存入磁盘，不再存储到内存
- 消费者要消费消息时才会从磁盘中读取并加载到内存（可以提前缓存部分消息到内存，最多2048条）

在3.12版本后，所有队列都是Lazy Queue模式，无法更改。

## 消费者可靠性

### 消费者确认机制

消费者确认机制（Consumer Acknowledgement）是为了确认消费者是否成功处理消息。当消费者处理消息结束后，应该向RabbitMQ发送一个回执，告知RabbitMQ自己消息处理状态：

- ack:成功处理消息，RabbitMQ从队列中删除该消息
- nack:消息处理失败，RabbitMQ需要再次投递消息
- reject:消息处理失败并拒绝该消息，RabbitMQ从队列中删除该消息

SpringAMQP已经实现了消息确认功能。并允许我们通过配置文件选择ACK处理方式，有三种方式：

- none：不处理。即消息投递给消费者后立刻ack，消息会立刻从MQ删除。非常不安全，不建议使用

- manual：手动模式。需要自己在业务代码中调用api，发送ack或reject，存在业务入侵，但更灵活

- auto：自动模式。SpringAMQP利用AOP对我们的消息处理逻辑做了环绕增强，当业务正常执行时则自动返回ack。当业务出现了异常时，根据异常判断返回不同结果：

  - 如果是业务异常，会自动返回nack

  - 如果是消息处理或校验异常，自动返回reject

  - ```yaml
    spring:
    	rabbitmq:
    		simple:
    			prefetch: 1
    			acknowledge-mode: none # none,关闭ack；manual，手动ack；auto:自动ack
    ```

### 失败重试机制

SpringAMQP提供了消费者失败重试机制，在消费者出现异常时利用本地重试，而不是无限的requeue到mq。我们可以通过在application.yaml文件中添加配置来开启重试机制：

```yaml
spring:
	rabbitmq:
		simple:
			prefetch: 1
			retry:
				enabled: true # 开启消费者
```

在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要一MessageRecoverer接口来处理，它包含3种不同的实现：

- RejectAndDontRequeueRecoverer: 重试次数耗尽，直接reject，丢弃消息。默认就是这种方式
- ImmediateRequeueMessageRecoverer:重试耗尽后，返回nack，消息重新入队
- RepublishMessageRecoverer:重试耗尽后，将失败消息投递到指定的交换机

将失败策略改为RepublishMessageRecoverer：

1. 首先，定义接收失败消息的交换机、队列及其绑定关系。

2. 然后，定义RepublishMessageRecoverer：

   ```java
   @Bean
   public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate) {
       return new RepublishMessageRecoverer(rabbitTemplate, "error.direct", "error");
   }
   ```

## 业务幂等性

**幂等**是一个数学概念，用函数表达式来描述是这样的：f(x)=f(f(x))。在程序开发中，则是指同一个业务，执行一次或多次对业务状态的影响是一致的。

![image-20250124120052902](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250124120052902.png)

### 唯一消息id

方案一，是给每个消息都设置一个唯一id，利用id区分是否是重复消息：

1. 每一条消息都生成一个唯一的id，与消息一起投递给消费者。
2. 消费者接收到消息后处理自己的业务，业务处理成功后将消息ID保存到数据库
3. 如果下次又收到相同消息，去数据库查询判断是否存在，存在则为重复消息放弃处理。

```java
@Bean
public MessageConverter messageConverter(){
    // 1.定义消息转换器
    Jackson2JsonMessageConverter jjmc  = new Jackson2JsonMessageConverter();
    // 2. 配置自动创建消息id，用于识别不同消息，也可以在业务中基于ID判断是否是重复消息
    jjmc.setCreateMessageIds(true);
    return jjmc;
}
```

方案二，基于业务逻辑新判断

总结：

如何保证支付服务与交易服务之间的订单状态一致性？

- 首先，支付服务会正在用户支付成功以后利用MQ消息通知交易服务，完成订单状态同步。
- 其次，为了保证MQ消息的可靠性，我们采用了生产者确认机制、消费者确认、消费者失败重试等策略，确保消息投递和处理的可靠性。同时也开启了MQ的持久化，避免因服务宕机导致消息丢失。
- 最后，我们还在交易服务更新订单状态是做了业务幂等判断，避免因消息重复消费导致订单状态异常。

## 延迟消息

**延迟消息**：发送者发送消息时指定一个时间，消费者不会立刻收到消息，而是在指定时间之后才收到消息。

**延迟任务**：设置在一定时间之后才执行的任务

![image-20250124133906119](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250124133906119.png)

### 死信交换机

当一个队列中的消息满足下列情况之一时，就会成为**死信**（dead letter）：

- 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false
- 消息是一个过期消息（达到了队列或消息本身设置的过期时间），超时无人消费
- 要投递的队列消息堆积满了，最早的消息可能成为死信

如果队列通过dead-letter-exchange属性指定了一个交换机，那么该队列中的死信就会投递到这个交换机中。这个交换机称为**死信交换机**（Dead Letter Exchange，简称DLX）。

![image-20250124134655696](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250124134655696.png)

### 延迟消息插件

这个插件可以将普通交换机改装为支持延迟消息功能的交换机，当消息投递到交换机后可以暂存一定时间，到期后再投递到队列。

![image-20250124140250055](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250124140250055.png)

插件下载地址：https://b11et3un53m.feishu.cn/wiki/A9SawKUxsikJ6dk3icacVWb4n3g#share-MdQMdRVS6oOZiQxWWG9cz8ZMngF

### 安装

因为我们是基于Docker安装，所以需要先查看RabbitMQ的插件目录对应的数据卷。

```Shell
docker volume inspect mq-plugins
```

结果如下：

```JSON
[
    {
        "CreatedAt": "2024-06-19T09:22:59+08:00",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/mq-plugins/_data",
        "Name": "mq-plugins",
        "Options": null,
        "Scope": "local"
    }
]
```

插件目录被挂载到了`/var/lib/docker/volumes/mq-plugins/_data`这个目录，我们上传插件到该目录下。

接下来执行命令，安装插件：

```Shell
docker exec -it mq rabbitmq-plugins enable rabbitmq_delayed_message_exchange
```

### 声明延迟交换机

基于注解方式：

```java
@RabbitListener(bindings = @QueueBinding(
	value = @Queue(name = "delay.queue", durable = "true"),
    exchange = @Exchange(name = "delay.direct", delayed = "true"),
    key = "delay"
))
public void listenDelayMessage(String msg) {
	log.info("接收到delay.queue的延迟消息：{}", msg);
}
```

基于@Bean的方式：

```java
@sl4j
@Configuration
public class DelayExchangeConfig {
    @Bean
    public DirectExchange delayExchange(){
        return ExchangeBuilder
            	.directExchange("delay.direct") // 指定交换机类型和名称
            	.delayed()	// 设置delay的属性为true
            	.durable(true)	// 持久化
            	.build();
    }
    
    @Bean
    public Queue delayedQueue(){
		return new Queue("delay.queue");
    }
    
    @Bean
    public Binding delayQueueBinding(){
		return BindingBuilder.bind(delayedQueue()).to(delayExchange()).with("delay");
    }
}
```

发送消息时需要通过消息头x-delay来设置过期时间：

```java
@Test
void testPublisherDelayMessage() {
    // 1.创建信息
    String message = "hello, delayed message";
    // 2.发送消息，利用消息后置处理器添加消息头
    rabbitTemplate.convertAndSend("delay.direct", "delay", message, new MessagePostProcessor() {
        @Override
        public Message postProcessMessage(Message message) throws AmqpException {
            // 添加延迟消息属性
            message.getMessageProperties().setDelay(5000);
            return message;
        }
    })
}
```

![image-20250124192639733](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250124192639733.png)

# Elasticsearch

高性能分布式搜索引擎

- 搜索引擎技术排名：
  1. Elasticsearch：开源的分布式搜索引擎
  2. Splunk：商业项目
  3. Solr：Apache的开源搜索引擎

## 认识和安装

Lucene 是一个Java语言的搜索引擎类库，是Apache公司的顶级项目，由DougCutting于1999年研发。官网地址：https://lucene.apache.org/

Lucene的优势：

- 易扩展
- 高性能（基于倒排索引）



- 2004年Shay Banon基于Lucene开发了Compass
- 2010年Shay Banon 重写了Compass，取名为Elasticsearch。
- 官网地址：https://www.elastic.co/cn/，目前最新的版本是：8.x.x
- elasticsearch具备下列优势：
  - 支持分布式，可水平扩展
  - 提供Restful接口，可被任何语言调用

elasticsearch结合kibana、Logstash、Beats，是一整套技术栈，被叫做ELK。被广泛应用在日志数据分析、实时监控等领域。

![image-20250125233856518](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250125233856518.png)

安装elasticsearch

```bash
docker run -d \
  --name es \
  -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  -e "discovery.type=single-node" \
  -v es-data:/usr/share/elasticsearch/data \
  -v es-plugins:/usr/share/elasticsearch/plugins \
  --privileged \
  --network hm-net \
  -p 9200:9200 \
  -p 9300:9300 \
  elasticsearch:7.12.1
```

安装完成后，访问9200端口，即可看到响应的Elasticsearch服务的基本信息

安装Kibana

```bash
docker run -d \
--name kibana \
-e ELASTICSEARCH_HOSTS=http://es:9200 \
--network=hm-net \
-p 5601:5601  \
kibana:7.12.1
```

安装完成后，直接访问5601端口，即可看到控制台页面

## 倒排索引

传统数据库（如MySQL）采用正向索引



elaticsearch 采用倒排索引：

- 文档（document）：每条数据就是一个文档
- 词条（term）：文档按照语义分成的词语

![image-20250126010707025](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250126010707025.png)

![image-20250126010922785](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250126010922785.png)



不同服务间最好要添加到同一网络下，不然互相访问会出问题

### mysql与elasticsearch

我们统一的把mysql与elasticsearch的概念做一下对比：

| **MySQL** | **Elasticsearch** | **说明**                                                     |
| :-------- | :---------------- | :----------------------------------------------------------- |
| Table     | Index             | 索引(index)，就是文档的集合，类似数据库的表(table)           |
| Row       | Document          | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |
| Column    | Field             | 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） |
| Schema    | Mapping           | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |
| SQL       | DSL               | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |

那是不是说，我们学习了elasticsearch就不再需要mysql了呢？

并不是如此，两者各自有自己的擅长之处：

-  Mysql：擅长事务类型操作，可以确保数据的安全和一致性 
-  Elasticsearch：擅长海量数据的搜索、分析、计算 

因此在企业中，往往是两者结合使用：

- 对安全性要求较高的写操作，使用mysql实现
- 对查询性能要求较高的搜索需求，使用elasticsearch实现
- 两者再基于某种方式，实现数据的同步，保证一致性

什么是正向索引？

- 基于文档id创建索引。根据id查询快，但是查询词条时必须先找到文档，而后判断是否包含词条

什么是倒序索引？

- 对文档内容分词，对词条创建索引，并记录词条所在文档的id。查询时先根据词条查询到文档id，而后根据文档id查询文档

## IK分词器

中文分词往往需要根据语义分析，比较复杂，这就需要用到中文分词器，例如IK分词器。IK分词器是林良益在2006年开源发布的，其采用的正向迭代最细粒度切分算法一直沿用至今。

IK分词器包含两种模式：

-  `ik_smart`：智能语义切分 
-  `ik_max_word`：最细粒度切分 

我们在Kibana的DevTools上来测试分词器，首先测试Elasticsearch官方提供的标准分词器：

```JSON
POST /_analyze
{
  "analyzer": "standard",
  "text": "黑马程序员学习java太棒了"
}
```

POST /_analyze{  "analyzer": "standard",  "text": "黑马程序员学习java太棒了"}

![image-20250126014248172](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250126014248172.png)

![image-20250126014306183](C:\Users\29326\AppData\Roaming\Typora\typora-user-images\image-20250126014306183.png)



## 基础概念

elasticsearch中的文档数据会被序列化为json格式后存储在elasticsearch中。

索引（index)：相同类型的文档的集合

映射（mapping）:索引中文档的字段约束信息，类似表的结构约束

## 索引库操作

### Mapping映射属性

mapping是对索引库中文档的约束，常见的mapping属性包括：

- type: 字段数据类型，常见的简单类型有：
  - 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
  - 数值：long、integer、short、byte、double、float
  - 布尔：boolean
  - 日期：date
  - 对象：object
- index：是否创建索引，默认为true
- analyzer：使用哪种分词器
- properties：该字段的子字段

### 操作

Elasticsearch提供的所有API都是Restful的接口，遵循Restful的基本规范：

| 接口类型 | 请求方式 | 请求路径    | 请求参数   |                  |
| -------- | -------- | ----------- | ---------- | ---------------- |
| 查询用户 | GET      | /users/{id} | 路径中的id |                  |
| 新增用户 | POST     | /users      |            | json格式user对象 |
| 修改用户 | PUT      | /users/{id} | 路径中的id | json格式对象     |
| 删除用户 | DELETE   | /users/{id} | 路径中的id |                  |

创建索引库和mapping的请求语法如下：

```
PUT /索引库名称
{
	"mappings": {
		"properties": {
			"字段名": {
				"type": "text",
				"analyzer": "ik_smart"
			},
			"字段名2": {
				"type": "keyword",
				"index": "false"
			},
			"字段名3": {
				"properties": {
					"子字段": {
						"type": "keyword"
					}
				}
			},
			// ....
		}
	}
}
```

查看语法：GET /索引库名 删除语法：DELETE /索引库名



索引库和mapping一旦创建无法修改，但是可以添加新的字段，语法如下：

```
PUT /索引库名/_mapping
{
	"properties": {
		"新字段名": {
			"type": "integer"
		}
	}
}
```

## 文档操作

### 文档CRUD

新增文档的请求格式如下:

```json
POST /索引库名/_doc/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    "字段3": {
        "子属性1": "值3",
        "子属性2": "值4"
    }
}
```

其它类似

不同点：

方式一： 全量修改，会删除旧文档，添加新文档

```json
PUT /索引库名/_doc/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    // .....
}
```

方式二：增量修改，修改指定字段值

```json
POST /索引库名/_update/文档id
{
    "doc": {
        "字段名": "新的值",
    }
}
```

### 批量处理

Elasticsearch中允许通过一次请求中携带多次文档操作，也就是批量处理，语法格式如下：

```json
POST /_bulk
{ "index" : { "_index": "索引库名", "_id" : "1"}}
{ "字段1": "值1","字段2": "值2"}
{}
```

